# Название проекта:
Автоматизация модерации комментариев в интернет-магазине с использованием модели BERT

# Описание проекта:
Интернет-магазин запускает новый сервис, позволяющий пользователям редактировать и дополнять описания товаров в стиле вики-сообществ. В рамках этого сервиса клиенты могут предлагать правки и комментировать изменения других пользователей. Важной задачей является создание инструмента для поиска токсичных комментариев и отправки их на модерацию.

# Цель проекта:
Разработать модель машинного обучения на основе технологии BERT для классификации комментариев на позитивные и негативные, достигая метрики качества F1 не меньше 0.73.

# Задачи проекта:
1. Загрузка и подготовка данных:
 - Изучение и анализ предоставленного набора данных.
 - Предобработка текстовых данных для машинного обучения.
2. Обучение моделей:
- Реализация модели BERT для анализа текста.
- Сравнение производительности BERT с другими моделями машинного обучения.
3. Оценка эффективности моделей:
- Оценка моделей на основе метрики F1.
- Анализ ошибок и точности моделей.
  
# Технологии и инструменты:
1. Язык программирования: Python
2. Библиотеки для обработки данных:
    - pandas
    - NumPy
3. Библиотеки для визуализации данных:
    - Matplotlib
    - seaborn
4. Машинное обучение и моделирование:
    - scikit-learn (включая функции для разбиения данных, валидации модели и преобразования признаков)
    - lightgbm (LGBMClassifier)
    - catboost (CatBoostClassifier)
    - transformers (для работы с предобученными моделями BERT и токенизации)
5. Библиотеки для работы с текстом:
    - nltk (для лемматизации, работы со стоп-словами и теггирования)
    - re (для регулярных выражений)
6. Инструменты для управления итерациями и временем:
    - tqdm (для отслеживания прогресса обучения моделей)
    - time (для измерения времени выполнения кода)
    - os (для работы с файловой системой операционной системы)
7. Платформы для работы с моделями глубокого обучения:
    - PyTorch (включая AutoModel и AutoTokenizer для работы с моделями из transformers)
## План проекта
1. Подготовка данных
- Загрузка данных: Импортировать данные из источника и ознакомиться с их структурой.
- Предварительная обработка и анализ данных: Проверить на наличие пропусков и аномалий. Применить необходимые методы очистки и предобработки данных. Визуальный анализ.
- Лематизация: Очищяем текст от лишних символов, проставляем метки в тексте, леметизируем текст и удаляем не информативные лова и предлоги.
2. Подготовка признаков
- Токенизируем очищенный текст.
- Уменишаем колличество данных для успешного эмбендинга.
- Поиск веса классов преобразованием в эмбендинг, моделью Берт
- Объявляем признаки и таргет в переменные.
- Делим данные на выборки 40/30/30 %
- Увеличение классов в выборке
3. Построение и оценка моделей
- Выбор моделей: Определить набор моделей машинного обучения для экспериментов.
- Тюнинг гиперпараметров: Использовать методы поиска гиперпараметров (например, GridSearchCV, RandomizedSearchCV) для нахождения оптимальных настроек моделей.
- Кросс-валидация: Применить кросс-валидацию для оценки качества моделей на различных наборах данных.
4. Анализ моделей
- Сравнение с константной моделью.
- Анализ результатов: Сравнить результаты различных моделей и выбрать наиболее подходящую
- Оценка на тестовой выборке: Проверить финальную модель на тестовой выборке для оценки её способности к обобщению.
- Метрики качества: Использовать F1 для оценки точности предсказаний модели.
5. Выводы
- Рекомендации: Предложить рекомендации для дальнейшего улучшения модели и возможных путей применения результатов проекта.
