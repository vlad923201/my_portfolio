Название проекта:
Автоматизация модерации комментариев в интернет-магазине с использованием модели BERT

Описание проекта:
Интернет-магазин запускает новый сервис, позволяющий пользователям редактировать и дополнять описания товаров в стиле вики-сообществ. В рамках этого сервиса клиенты могут предлагать правки и комментировать изменения других пользователей. Важной задачей является создание инструмента для поиска токсичных комментариев и отправки их на модерацию.

Цель проекта:
Разработать модель машинного обучения на основе технологии BERT для классификации комментариев на позитивные и негативные, достигая метрики качества F1 не меньше 0.73.

Задачи проекта:
Загрузка и подготовка данных:
Изучение и анализ предоставленного набора данных.
Предобработка текстовых данных для машинного обучения.
Обучение моделей:
Реализация модели BERT для анализа текста.
Сравнение производительности BERT с другими моделями машинного обучения.
Оценка эффективности моделей:
Оценка моделей на основе метрики F1.
Анализ ошибок и точности моделей.
Технологии и инструменты:
Язык программирования: Python
Библиотеки для обработки данных:
pandas
NumPy
Библиотеки для визуализации данных:
Matplotlib
seaborn
Машинное обучение и моделирование:
scikit-learn (включая функции для разбиения данных, валидации модели и преобразования признаков)
lightgbm (LGBMClassifier)
catboost (CatBoostClassifier)
transformers (для работы с предобученными моделями BERT и токенизации)
Библиотеки для работы с текстом:
nltk (для лемматизации, работы со стоп-словами и теггирования)
re (для регулярных выражений)
Инструменты для управления итерациями и временем:
tqdm (для отслеживания прогресса обучения моделей)
time (для измерения времени выполнения кода)
os (для работы с файловой системой операционной системы)
Платформы для работы с моделями глубокого обучения:
PyTorch (включая AutoModel и AutoTokenizer для работы с моделями из transformers)
План проекта
Подготовка данных
Загрузка данных: Импортировать данные из источника и ознакомиться с их структурой.
Предварительная обработка и анализ данных: Проверить на наличие пропусков и аномалий. Применить необходимые методы очистки и предобработки данных. Визуальный анализ.
Лематизация: Очищяем текст от лишних символов, проставляем метки в тексте, леметизируем текст и удаляем не информативные лова и предлоги.
Подготовка признаков
Токенизируем очищенный текст.
Уменишаем колличество данных для успешного эмбендинга.
Поиск веса классов преобразованием в эмбендинг, моделью Берт
Объявляем признаки и таргет в переменные.
Делим данные на выборки 40/30/30 %
Увеличение классов в выборке
Построение и оценка моделей
Выбор моделей: Определить набор моделей машинного обучения для экспериментов.
Тюнинг гиперпараметров: Использовать методы поиска гиперпараметров (например, GridSearchCV, RandomizedSearchCV) для нахождения оптимальных настроек моделей.
Кросс-валидация: Применить кросс-валидацию для оценки качества моделей на различных наборах данных.
Анализ моделей
Сравнение с константной моделью.
Анализ результатов: Сравнить результаты различных моделей и выбрать наиболее подходящую
Оценка на тестовой выборке: Проверить финальную модель на тестовой выборке для оценки её способности к обобщению.
Метрики качества: Использовать F1 для оценки точности предсказаний модели.
Выводы
Рекомендации: Предложить рекомендации для дальнейшего улучшения модели и возможных путей применения результатов проекта.